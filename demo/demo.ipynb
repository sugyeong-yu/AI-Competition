{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데모 프로그램"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ysk00\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\ysk00\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\ysk00\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:245: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\ysk00\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\ysk00\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\ysk00\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\ysk00\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\ysk00\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\ysk00\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\ysk00\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\ysk00\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\ysk00\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\ysk00\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Users\\ysk00\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\ysk00\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\ysk00\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\ysk00\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\ysk00\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      ">> model loaded.\n",
      ">> Running..\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "- tkinter 간략한 강좌\n",
    "http://pythonstudy.xyz/python/article/120-Tkinter-%EC%86%8C%EA%B0%9C\n",
    "\n",
    "- 컬러 차트\n",
    "http://www.science.smith.edu/dftwiki/index.php/Color_Charts_for_TKinter\n",
    "'''\n",
    "import tkinter\n",
    "import tkinter.font\n",
    "import cv2\n",
    "import numpy as np\n",
    "import dlib\n",
    "import PIL.Image, PIL.ImageTk\n",
    "import time\n",
    "from keras.models import load_model\n",
    "from imutils.face_utils import FaceAligner\n",
    "\n",
    "class App:\n",
    "    def __init__(self, window, window_title, video_source=0):\n",
    "        self.thresh = 0.5 # 값 범위: 0.0 ~ 1.0\n",
    "        \n",
    "        self.win_width = 1000\n",
    "        self.win_height = 600\n",
    "        self.bDetect = False\n",
    "        self.bPause = False\n",
    "        \n",
    "        self.window = window\n",
    "        self.window.title(window_title)\n",
    "        self.window.geometry(\"%dx%d+0+0\" % (self.win_width, self.win_height))\n",
    "        self.window.resizable(False, False)\n",
    "        self.video_source = video_source\n",
    "\n",
    "        ### open video source (by default this will try to open the computer webcam)\n",
    "        self.vid = MyVideoCapture(self.video_source)\n",
    "\n",
    "        ### Create a canvas that can fit the above video source size\n",
    "        self.wholewidth = int(self.win_height * 0.76)\n",
    "        self.wholeheight = int(self.wholewidth * (480 / 640))\n",
    "        self.facewidth = int(self.win_height * 0.25)\n",
    "        \n",
    "        # frame\n",
    "        img_faceframe = PIL.ImageTk.PhotoImage(file='./rc/faceframe.png')\n",
    "        self.lbl_faceframe = tkinter.Label(image=img_faceframe)\n",
    "        self.lbl_faceframe.image = img_faceframe\n",
    "        img_frameframe = PIL.ImageTk.PhotoImage(file='./rc/frameframe.png')\n",
    "        self.lbl_frameframe = tkinter.Label(image=img_frameframe)\n",
    "        self.lbl_frameframe.image = img_frameframe\n",
    "        \n",
    "        self.lbl_faceframe.place(relx=0.02,rely=0.03)\n",
    "        self.lbl_frameframe.place(relx=0.47,rely=0.03)\n",
    "        \n",
    "        \n",
    "        # label\n",
    "        img_logo = PIL.ImageTk.PhotoImage(file='./rc/logo.png')\n",
    "        self.lbl_logo = tkinter.Label(image=img_logo)\n",
    "        self.lbl_logo.image = img_logo\n",
    "        self.lbl_logo.place(relx=0.47,rely=0.73)\n",
    "        \n",
    "        font = tkinter.font.Font(family=\"Times\", size=16)\n",
    "        self.lbl_text1 = tkinter.Label(text=\"DETECTION\", width=12, font=font, bg='gray75')\n",
    "        self.lbl_text2 = tkinter.Label(text=\"RESULT\", width=12, font=font, bg='gray75')\n",
    "        self.lbl_text1.place(relx=0.07, rely=0.13)\n",
    "        self.lbl_text2.place(relx=0.26, rely=0.13)\n",
    "        \n",
    "        font2 = tkinter.font.Font(family=\"Times\", size=14)\n",
    "        self.lbl_preds = []\n",
    "        self.lbl_preds.append(tkinter.Label(text=\"\", width=15, height=2, font=font2, bg='gray75'))\n",
    "        self.lbl_preds.append(tkinter.Label(text=\"\", width=15, height=2, font=font2, bg='gray75'))\n",
    "        self.lbl_preds[0].place(relx=0.26, rely=0.33)\n",
    "        self.lbl_preds[1].place(relx=0.26, rely=0.65)\n",
    "        self.lbl_msgs = []\n",
    "        self.lbl_msgs.append(tkinter.Label(text=\"\", width=15, height=2, font=font2, bg='gray75'))\n",
    "        self.lbl_msgs.append(tkinter.Label(text=\"\", width=15, height=2, font=font2, bg='gray75'))\n",
    "        self.lbl_msgs[0].place(relx=0.26, rely=0.40)\n",
    "        self.lbl_msgs[1].place(relx=0.26, rely=0.72)\n",
    "                            \n",
    "\n",
    "        # video\n",
    "        self.canvas_faces = []\n",
    "        self.canvas_faces.append(tkinter.Canvas(window, width = self.facewidth, height = self.facewidth, highlightthickness=0))\n",
    "        self.canvas_faces.append(tkinter.Canvas(window, width = self.facewidth, height = self.facewidth, highlightthickness=0))\n",
    "        self.canvas_frame = tkinter.Canvas(window, width = self.wholewidth, height = self.wholeheight, highlightthickness=0)\n",
    "        \n",
    "        self.canvas_faces[0].place(relx=0.07, rely=0.25)\n",
    "        self.canvas_faces[1].place(relx=0.07, rely=0.57)\n",
    "        self.canvas_frame.place(relx=0.495, rely=0.07)\n",
    "\n",
    "        # Button\n",
    "        font2 = tkinter.font.Font(family=\"Times\", size=10)\n",
    "        self.btn_pause=tkinter.Button(window, text=\"Pause\", font=font2, width=20, borderwidth=3, command=self.func_pause, bg=\"white\", activebackground='cornflower blue', highlightbackground='blue', relief='groove')\n",
    "        self.btn_pause.place(relx=0.57, rely=0.66)\n",
    "        \n",
    "        self.btn_detect=tkinter.Button(window, text=\"Detect\", font=font2, width=20, borderwidth=3, command=self.func_detect, bg=\"white\", activebackground='cornflower blue', highlightbackground='blue', relief='groove')\n",
    "        self.btn_detect.place(relx=0.75, rely=0.66)\n",
    "\n",
    "        # After it is called once, the update method will be automatically called every delay milliseconds\n",
    "        self.delay = 15\n",
    "        self.update()\n",
    "\n",
    "        print('>> Running..')\n",
    "        self.window.mainloop()\n",
    "\n",
    "    def func_pause(self):\n",
    "        self.bPause = not self.bPause\n",
    "        if self.bPause:\n",
    "            self.btn_pause['bg'] = \"cornflower blue\"\n",
    "        else:\n",
    "            self.btn_pause['bg'] = \"white\"\n",
    "    \n",
    "    def func_detect(self):\n",
    "        if not self.bPause:\n",
    "            self.bDetect = not self.bDetect\n",
    "            if self.bDetect:\n",
    "                self.btn_detect['bg'] = \"cornflower blue\"\n",
    "            else:\n",
    "                self.btn_detect['bg'] = \"white\"\n",
    "        else:\n",
    "            print(\"[ERROR] Can't detect the faces when the button 'pause' pressed\")\n",
    "    \n",
    "            \n",
    "    def update(self):\n",
    "        ret, frame, rects, aligns = self.vid.detect_faces()\n",
    "        if ret and (frame is not None):\n",
    "            if not self.bPause:\n",
    "                faces = []\n",
    "                faces.append(cv2.imread('./rc/empty.png'))\n",
    "                faces.append(cv2.imread('./rc/empty.png'))\n",
    "                \n",
    "                if self.bDetect:\n",
    "                    for i in range(2):\n",
    "                        self.lbl_preds[i].config(text=\"\", bg='gray75')\n",
    "                        self.lbl_msgs[i].config(text=\"\")\n",
    "                    \n",
    "                    if rects:\n",
    "                        for i, (rect, aligned) in enumerate(zip(rects, aligns)):\n",
    "                            msg, (ys,ye,xs,xe) = self.vid.check_face(frame, rect)\n",
    "                            size = xe-xs\n",
    "                            \n",
    "                            # 얼굴 영역만 자르기\n",
    "                            faces[i] = frame[ys:ye, xs:xe].copy()\n",
    "                            \n",
    "                            if msg == \"\":\n",
    "                                score = self.vid.detect_spoof(aligned)\n",
    "\n",
    "                                if score > self.thresh:   color = (0,255,0); pred = \"live\"; bg = 'green2'\n",
    "                                else:                     color = (255,0,0); pred = \"fake\"; bg = 'red'\n",
    "                                    \n",
    "                            else:\n",
    "                                color = (255,192,0); pred = \"undetectable\"; bg = 'orange'\n",
    "\n",
    "                            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "                            textsize = cv2.getTextSize(pred, font, 1, 2)[0]\n",
    "                            textX = xs + (size - textsize[0]) // 2\n",
    "                            cv2.putText(frame, pred, (textX, ys-20), font, 1, color, 2)\n",
    "\n",
    "                            cv2.rectangle(frame, (xs,ys), (xe,ye), color, 2)\n",
    "                            \n",
    "                            self.lbl_preds[i].config(text=pred, bg=bg)\n",
    "                            self.lbl_msgs[i].config(text=msg)\n",
    "            \n",
    "                    \n",
    "                # 비디오 위젯 업데이트\n",
    "                self.faces = [None, None]\n",
    "                for i in range(2):\n",
    "                    faces[i] = cv2.resize(faces[i], (self.facewidth, self.facewidth))\n",
    "                    self.faces[i] = PIL.ImageTk.PhotoImage(image = PIL.Image.fromarray(faces[i]))\n",
    "                    self.canvas_faces[i].create_image(0, 0, image = self.faces[i], anchor = tkinter.NW)\n",
    "\n",
    "                frame = cv2.resize(frame, (self.wholewidth, self.wholeheight))\n",
    "                self.frame = PIL.ImageTk.PhotoImage(image = PIL.Image.fromarray(frame))\n",
    "                self.canvas_frame.create_image(0, 0, image = self.frame, anchor = tkinter.NW)\n",
    "                \n",
    "        self.window.after(self.delay, self.update)\n",
    "\n",
    "            \n",
    "            \n",
    "class MyVideoCapture:\n",
    "    def __init__(self, video_source=0, facesize=256):\n",
    "        # Open the video source\n",
    "        self.cap = cv2.VideoCapture(video_source)\n",
    "        if not self.cap.isOpened():\n",
    "            raise ValueError(\"Unable to open video source\", video_source)\n",
    "\n",
    "        self.width = self.cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "        self.height = self.cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "        \n",
    "        self.detector = dlib.get_frontal_face_detector()\n",
    "        self.predictor = dlib.shape_predictor('./trained_model/shape_predictor_5_face_landmarks.dat')\n",
    "        self.fa = FaceAligner(self.predictor, desiredLeftEye=(0.35, 0.35), desiredFaceWidth=facesize)\n",
    "        \n",
    "        self.model = load_model('./trained_model/NUAA+CASIA-22-0.2004.hdf5')\n",
    "        print('>> model loaded.')\n",
    "\n",
    "        \n",
    "    def detect_faces(self):\n",
    "        ret, frame = self.cap.read()\n",
    "        if not ret:\n",
    "            return (ret, None, None, None)\n",
    "        \n",
    "        frame = cv2.flip(frame, 1)\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
    "        rects = self.detector(frame)\n",
    "        \n",
    "        if len(rects) > 0:\n",
    "            rects = sorted(rects, key=lambda x:x.area(), reverse=True)\n",
    "\n",
    "            faces = []\n",
    "            aligns = []\n",
    "            for i, rect in enumerate(rects):\n",
    "                if i>=2: break\n",
    "\n",
    "                xs, ys, xe, ye = rect.left(), rect.top(), rect.right(), rect.bottom()\n",
    "                w,h = xe-xs, ye-ys\n",
    "\n",
    "                if xs < 0 or xs >= self.width or ys < 0 or ye >= self.height or w <= 0 or h <= 0:\n",
    "                    continue\n",
    "                \n",
    "                aligned = self.fa.align(frame, gray, rect)\n",
    "                \n",
    "                faces.append(rect)\n",
    "                aligns.append(aligned)\n",
    "                \n",
    "            return (ret, frame, faces, aligns)\n",
    "\n",
    "        else:\n",
    "            return (ret, frame, None, None)\n",
    "            \n",
    "            \n",
    "    def detect_spoof(self, img, th=0.5):\n",
    "        img = img.astype('float32') / 255.0\n",
    "        score = self.model.predict(np.expand_dims(img, axis=0)).squeeze()\n",
    "        return score\n",
    "    \n",
    "    def check_face(self, img, rect):\n",
    "        # 얼굴 특징점 검출\n",
    "        shape = self.predictor(img, rect)\n",
    "        rEye = ((shape.part(0).x + shape.part(1).x) // 2, (shape.part(0).y + shape.part(1).y) // 2)\n",
    "        lEye = ((shape.part(2).x + shape.part(3).x) // 2, (shape.part(2).y + shape.part(3).y) // 2)\n",
    "        nose = (shape.part(4).x, shape.part(4).y)\n",
    "\n",
    "        # 얼굴 위치 및 길이 정보 계산\n",
    "        xs, xe, ys, ye = rect.left(), rect.right(), rect.top(), rect.bottom()\n",
    "        l = max(xe-xs,ye-ys)\n",
    "        \n",
    "        # 얼굴 제약 조건 검사\n",
    "        if self.reject_ipd(rEye, lEye, nose, self.width, muRatio=15.0):\n",
    "            return 'More closer', (ys, ys+l, xs, xs+l)\n",
    "        \n",
    "        if self.reject_angle(rEye, lEye, nose):\n",
    "            return \"Keep your head\\nstraight\", (ys, ys+l, xs, xs+l)\n",
    "        \n",
    "        return \"\", (ys, ys+l, xs, xs+l)\n",
    "        \n",
    "    \n",
    "    def reject_ipd(self, lEye, rEye, nose, width, muRatio=28.8, rhoRatio=3.6, alpha=2.0):\n",
    "        '''\n",
    "        @ brief\n",
    "            Check IPD(inter pupillary distance) in the face\n",
    "\n",
    "        @ params\n",
    "        img: numpy array\n",
    "            input image\n",
    "        width: int\n",
    "            width of the input image\n",
    "        muRatio: float (default=28.8)\n",
    "            mean of the IPD ratio for reliable face spoofing detection\n",
    "        rhoRatio: float (default=3.6)\n",
    "            standard devidation of the IPD ratio\n",
    "        alpha: float (default=2.0)\n",
    "            desired valid IPD range level\n",
    "        '''\n",
    "        ipd = abs(rEye[0]-lEye[0])\n",
    "\n",
    "        mu = width * muRatio / 100    # Ratios are based on the width of the input image\n",
    "        rho = width * rhoRatio / 100\n",
    "        \n",
    "        ## Reject or pass\n",
    "        if abs(ipd - mu) > alpha * rho:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "        \n",
    "    def reject_angle(self, lEye, rEye, nose, rollThres=10, yawThres=0.1):\n",
    "        '''\n",
    "        @ brief\n",
    "            Check the degree of rotation of the face\n",
    "\n",
    "        @ params\n",
    "        info: dict\n",
    "            dict of the face rectangle and landmarks\n",
    "        rollThres: int (default=10)\n",
    "            threshold of the roll rotation (unit: degree)\n",
    "        yawThres: float (default=0.1)\n",
    "            threshold of the yaw rotation\n",
    "        '''\n",
    "        ## Calulate angle of roll rotation(=in-plain rotation) of input face\n",
    "        slope = (rEye[1] - lEye[1]) / (rEye[0] - lEye[0] + 1e-7)\n",
    "        rad = np.arctan(slope)\n",
    "        deg = np.degrees(rad)\n",
    "        roll = abs(deg)\n",
    "        \n",
    "        ## Calculate ratio of yaw rotation of input face\n",
    "        eye2eyeVec = np.array([rEye[0]-lEye[0], rEye[1]-lEye[1]])             # eye2eye vector\n",
    "        eye2noseVec = np.array([nose[0]-lEye[0], nose[1]-lEye[1]])            # eye2nose vector\n",
    "        eye2eyeNorm = np.sqrt(np.dot(eye2eyeVec, eye2eyeVec))                 # norm of the eye2eye vector\n",
    "        projVecNorm = np.dot(eye2eyeVec, eye2noseVec) / (eye2eyeNorm + 1e-7)  # norm of the vector projected eye2nose vector into eye2eye vector\n",
    "        yaw = abs(projVecNorm/(eye2eyeNorm + 1e-7) - 0.5)                     # ratio between eye2eye distance and eye2nose distance\n",
    "\n",
    "        ## Reject or pass\n",
    "        if roll > rollThres or yaw > yawThres:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "        \n",
    "    \n",
    "    # Release the video source when the object is destroyed\n",
    "    def __del__(self):\n",
    "        if self.cap.isOpened():\n",
    "            self.cap.release()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Create a window and pass it to the Application object\n",
    "    App(tkinter.Tk(), \"SMU - Face Spoofing Detector\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
